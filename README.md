ğŸ§  SafeNet â€“ AI-Powered Social Media for Sensitive Image Detection

SafeNet is a modern social media web application built with React + Vite and integrated with an AI model (EfficientNet-B0) to automatically detect and block sensitive or gory images before they are published.
The goal of SafeNet is to create a safe, positive, and responsible online community by preventing the spread of disturbing content.

ğŸš€ Features

ğŸ§© User authentication (register, login, logout)

ğŸ–¼ï¸ Post creation with image upload â€“ images are scanned by AI before posting

âš ï¸ Sensitive image detection (blood, gore, death scenes)

ğŸ’¬ User interactions â€“ view, like, and comment on posts

ğŸ”’ Automatic blocking or blurring of sensitive images

â˜ï¸ Cloud deployment â€“ React frontend on Vercel/Netlify, FastAPI backend on Render/Railway

âš™ï¸ Tech Stack
ğŸ§© Frontend

React + Vite â€“ lightweight and fast development environment with Hot Module Replacement

Axios â€“ API communication

Bootstrap / TailwindCSS â€“ responsive and clean UI

ğŸ§  Backend (AI + API)

FastAPI â€“ high-performance backend and RESTful API

TensorFlow / Keras â€“ training and serving the EfficientNet-B0 model

OpenCV / Pillow â€“ image preprocessing

PostgreSQL / MongoDB â€“ user, post, and moderation log storage

ğŸ§  AI Model â€“ EfficientNet-B0

The EfficientNet-B0 model is fine-tuned to classify images into two categories:

Normal: Safe and non-violent images

Sensitive: Gory or disturbing content (blood, injury, corpses)

When a user uploads an image, the backend sends it to the model via /analyze_image.
If the model predicts a sensitive probability > 0.7, the post is blocked and a warning message is shown.
ğŸ§ª How to Run Locally
1ï¸âƒ£ Install dependencies
# Frontend
cd frontend
npm install
npm run 

ğŸ‘¨â€ğŸ’» Authors

Project Name: SafeNet
Developed by: []
Year: 2025